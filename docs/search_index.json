[["index.html", "Workshop material", " Workshop material In the following link you will find the R routines developed for the workshop. Descargar "],["sesión-1--census-and-satellite-information.html", "Chapter 1 Sesión 1- Census and satellite information ", " Chapter 1 Sesión 1- Census and satellite information "],["use-of-satellite-imagery-and-sae.html", "1.1 Use of Satellite Imagery and SAE", " 1.1 Use of Satellite Imagery and SAE One of the pioneering articles in small area estimation was the paper by Singh, R, et al. (2002), which addressed crop yield estimation for the tehsils (sub-administrative units) of Rohtak district in Haryana, India. Raster images represent the world through a set of contiguous equally spaced cells known as pixels. These images contain information like a geographic information system and a coordinate reference system. Images store an identifier, a value in each pixel (or a vector with different values), and each cell is associated with a color scale. Images can be obtained in raw and processed forms. The former contains only color layers, while the latter also contains values that have been processed in each cell (vegetation indices, light intensity, type of vegetation). Raw information can be used to train desired features (roads, crop types, forest/non-forest). Fortunately, in Google Earth Engine, we find many processed indicators associated with a pixel. These indicators can be aggregated at a geographical area level. "],["satellite-image-data-sources.html", "1.2 Satellite Image Data Sources", " 1.2 Satellite Image Data Sources Some of the main sources of satellite images include: USGS Earth Explorer Land Processes Distributed Active Archive Center (LP DAAC) NASA Earthdata Search Copernicus Open Access Hub AWS Public Dataset - Landsat However, most of these sources are centralized within Google Earth Engine, which allows searching for satellite image data sources. GEE can be managed through APIs in different programming languages: JavaScript (by default), Python, and R (rgee package). Here’s the translation: "],["google-earth-engine.html", "1.3 Google Earth Engine", " 1.3 Google Earth Engine Create an account at this link. Once logged in, you can search for datasets of interest: Night Lights Image Upon searching for the dataset, you can open a code editor provided by Google in JavaScript. Copy and paste the syntax provided by the dataset search to visualize the raster image and obtain statements allowing for the retrieval of the dataset of interest later in R. Syntax in JavaScript Sure, here’s the translation of the instructions: "],["installing-rgee.html", "1.4 Installing rgee", " 1.4 Installing rgee Download and install Anaconda or Conda from here. Open Anaconda Prompt and set up a working environment (Python environment JAM2023) using the following commands: conda env list conda create -n JAM2023 python=3.9 activate JAM2023 pip install google-api-python-client pip install earthengine-api pip install numpy List available Python environments in Anaconda Prompt: conda env list Once you’ve identified the path of the JAM2023 environment, set it in R (remember to change \\ to /). Install reticulate and rgee, load packages for spatial processing, and set up the working environment as follows: library(reticulate) # Connection with Python library(rgee) # Connection with Google Earth Engine library(sf) # Package for handling geographic data library(dplyr) # Package for data processing library(magrittr) rgee_environment_dir = &quot;C:/Users/gnieto/Anaconda3/envs/JAM2023/python.exe&quot; # Set up Python (Sometimes not detected and R needs to be restarted) reticulate::use_python(rgee_environment_dir, required=T) rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = &quot;JAM2023&quot;) Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir) Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir) Once the environment is configured, you can initialize a Google Earth Engine session as follows: rgee::ee_Initialize(drive = T) Session started successfully Notes: Each session must be initialized with the command rgee::ee_Initialize(drive = T). JavaScript commands invoking methods with “.” are replaced by the dollar sign ($), for example: ee.ImageCollection().filterDate() # JavaScript ee$ImageCollection()$filterDate() # R ¡Claro! Aquí tienes la traducción de los pasos para descargar información satelital: 1.4.1 Downloading Satellite Information Step 1: Have the shapefiles ready. shape &lt;- read_sf(&quot;Shapefile/JAM2_cons.shp&quot;) plot(shape[&quot;geometry&quot;]) Shapefile Step 2: Select the image file you want to process, for example, night lights. lights &lt;- ee$ImageCollection(&quot;NOAA/DMSP-OLS/NIGHTTIME_LIGHTS&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2013-01-01&quot;, &quot;2014-01-01&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;stable_lights&quot;)) %&gt;% ee$ImageCollection$toBands() Step 3: Download the information. ## Takes about 10 minutes lights_shape &lt;- map(unique(shape$dam2), ~tryCatch(ee_extract( x = lights, y = shape[&quot;dam2&quot;] %&gt;% filter(dam2 == .x), ee$Reducer$mean(), sf = FALSE ) %&gt;% mutate(dam2 = .x), error = function(e)data.frame(dam2 = .x))) lights_shape %&lt;&gt;% bind_rows() tba(lights_shape, cap = &quot;Average of night lights&quot;) Tabla 1.1: Average standardized night lights dam2 stable_lights_mean 0101 0.9393 0102 1.6857 0103 1.6900 0201 -0.4380 0202 1.4627 0203 1.3519 0204 1.6333 0205 1.7522 0206 1.7522 0207 1.7444 Repeat the routine for: Soil type: crops-coverfraction (Percentage of crop cover) and urban-coverfraction (Percentage of urban cover) available at https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_Landcover_100m_Proba-V-C3_Global#description Travel time to the nearest hospital or clinic (accessibility) and travel time to the nearest hospital or clinic using non-motorized transport (accessibility_walking_only) information available at https://developers.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_healthcare_2019 Human modification, considering human settlements, agriculture, transportation, mining, energy production, and electrical infrastructure. You can find satellite information at the following link: https://developers.google.com/earth-engine/datasets/catalog/CSP_HM_GlobalHumanModification#description Paso 4: Consolidate the information. Tabla 1.2: Standardized satellite predictors dam2 stable_lights_mean crops.coverfraction_mean urban.coverfraction_mean gHM_mean accessibility_mean accessibility_walking_only_mean stable_lights_sum crops.coverfraction_sum urban.coverfraction_sum gHM_sum accessibility_sum accessibility_walking_only_sum 0101 0.9393 -0.5459 0.4390 0.5741 -0.7760 -0.9315 -1.2660 -0.5849 -0.8078 -1.1991 -0.6242 -0.8780 0102 1.6857 -0.7090 2.2891 1.8346 -0.8897 -1.2588 -1.7964 -0.5947 -1.2224 -1.2993 -0.6272 -0.8873 0103 1.6900 -0.3571 2.0344 1.7510 -0.8684 -1.2055 -1.6990 -0.5880 -1.0667 -1.2842 -0.6269 -0.8866 0201 -0.4380 -0.0874 -0.6524 -0.6504 0.0531 0.0511 1.0737 -0.1234 -0.6327 0.0186 -0.2048 -0.2380 0202 1.4627 -0.6237 1.1018 0.8775 -0.8226 -1.0846 -0.8523 -0.5884 0.1016 -1.1468 -0.6231 -0.8757 0203 1.3519 -0.6402 0.9281 0.8771 -0.6780 -0.9356 -0.8100 -0.5891 0.0754 -1.1302 -0.6160 -0.8673 0204 1.6333 -0.5050 0.9165 1.0157 -0.8334 -1.1168 -0.6630 -0.5781 0.0671 -1.1229 -0.6232 -0.8762 0205 1.7522 -0.6844 2.3011 1.8174 -0.8888 -1.2573 -1.2927 -0.5937 -0.0489 -1.2119 -0.6266 -0.8856 0206 1.7522 -0.4289 2.1777 1.8272 -0.8968 -1.2779 -1.8138 -0.5914 -1.3125 -1.3046 -0.6273 -0.8875 0207 1.7444 -0.4662 1.7771 1.6966 -0.8322 -1.1072 -1.5815 -0.5898 -1.0882 -1.2650 -0.6264 -0.8850 1.4.2 Night Lights 1.4.3 Crop Cover 1.4.4 Urban Cover 1.4.5 Human Modification Human Modification Sum Human Modification Satellite 1.4.6 Average Travel Time to Hospital Average Travel Time to Hospital Sum Average Travel Time to Hospital Satellite 1.4.7 Average Travel Time to Hospital by Non-Motorized Vehicle Average Travel Time to Hospital by Non-Motorized Vehicle Sum Average Travel Time to Hospital by Non-Motorized Vehicle Satellite "],["population-and-housing-censuses.html", "1.5 Population and Housing Censuses", " 1.5 Population and Housing Censuses It’s necessary to define the variables for the country you want to work with. As a first step, access to the country’s census data is required. You can access it from the following link: https://redatam.org/en/microdata, where you’ll find a .zip file with the microdata for the country. To read this dataset, you’ll need to use the redatam.open function from the redatam library. This function directly depends on the census dictionary from REDATAM software, which is a file with a .dicx extension and should be located in the same folder as the data being read. This is how an object is created within R that merges the dictionary with the microdata from the census database. After performing a process in R using REDATAM syntax, we have the following table: dam2 area1 sex2 age tiene_sanitario tiene_electricidad tiene_acueducto tiene_gas eliminar_basura tiene_internet material_paredes material_techo TRANMODE_PRIVATE_CAR ODDJOB WORKED 0101 1.0000 0.5087 2.5043 0.0019 0.7596 0.9545 0.7728 0.7804 0.9453 0.0095 0.7589 0.1472 0.0090 0.3488 0102 1.0000 0.4754 2.4689 0.0011 0.9064 0.9867 0.9181 0.9084 0.9882 0.0007 0.9060 0.0680 0.0126 0.2859 0103 1.0000 0.5037 2.2858 0.0152 0.6930 0.9741 0.7440 0.7362 0.9712 0.0028 0.6942 0.0491 0.0135 0.2819 0201 0.5147 0.5060 2.5517 0.0138 0.2342 0.8546 0.2955 0.6589 0.8386 0.0159 0.2215 0.1709 0.0077 0.3647 0202 0.9986 0.5376 2.7635 0.0028 0.3852 0.8236 0.4958 0.4138 0.6884 0.0014 0.5081 0.4489 0.0046 0.4512 0203 0.9754 0.5432 2.8765 0.0015 0.3326 0.7915 0.4864 0.3495 0.5945 0.0014 0.5135 0.5314 0.0042 0.4880 0204 1.0000 0.5300 2.6401 0.0042 0.5720 0.8835 0.6198 0.6166 0.7998 0.0016 0.5975 0.3197 0.0071 0.4125 0205 1.0000 0.5182 2.6644 0.0013 0.8060 0.9590 0.8347 0.8130 0.9091 0.0030 0.8234 0.3291 0.0068 0.4559 0206 1.0000 0.5157 2.3750 0.0290 0.0285 0.8879 0.1433 0.1516 0.9034 0.0258 0.0320 0.0639 0.0139 0.2914 0207 1.0000 0.5097 2.4257 0.0465 0.1581 0.8925 0.2551 0.2337 0.9198 0.0162 0.1512 0.0717 0.0169 0.3121 1.5.1 Mapas de las variables con información censal. "],["session-2--generalized-variance-function.html", "Chapter 2 Session 2- Generalized Variance Function", " Chapter 2 Session 2- Generalized Variance Function One of the most important inputs in the area model is the variance of the direct estimator at the domain level, which cannot be calculated directly. Accordingly, this value must be estimated from the data collected in each domain. However, in domains with very small sample sizes, these estimations will not perform well. Hence, it is very useful to use a smoothing model for variances to eliminate noise and volatility from these estimations and extract the true signal of the process. Hidiroglou (2019) states that \\(E_{\\mathscr{MP}}\\left(\\hat{\\theta}^{dir}_d\\right)=\\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta}\\) and \\(V_{\\mathscr{MP}}\\left(\\hat{\\theta}^{dir}_d\\right)=\\sigma_{u}^2+\\tilde{\\sigma}^2_{d}\\), where the subscript \\(\\mathscr{MP}\\) refers to the double inference that must be taken into account in these adjustments and defines the joint probability measure between the model and the sampling design. \\(\\mathscr{M}\\) refers to the probability measure induced by modeling and the inclusion of auxiliary covariates (\\(\\boldsymbol{x}_{d}\\)). \\(\\mathscr{MP}\\) refers to the probability measure induced by the complex sampling design that yields direct estimations. The solution proposed here is known as the Generalized Variance Function, which involves fitting a log-linear model to the estimated direct variance. Starting from the fact that an unbiased estimator of \\(\\sigma^2\\) denoted by \\(\\hat{\\sigma}^2\\) is available, it follows that: \\[ E_{\\mathscr{MP}}\\left(\\hat{\\sigma}_{d}^{2}\\right)=E_{\\mathscr{M}}\\left(E_{\\mathscr{P}}\\left(\\hat{\\sigma}_{d}^{2}\\right)\\right)=E_{\\mathscr{M}}\\left(\\sigma_{d}^{2}\\right)=\\tilde{\\sigma}_{d}^{2} \\] The above equality can be interpreted as an unbiased and simple estimator of \\(\\tilde{\\sigma}_{d}^{2}\\), denoted as \\(\\hat{\\sigma}_{d}^{2}\\). However, this sampling estimator is unstable when the sample size is small, which is precisely the dominant paradigm in small area estimation. Rivest and Belmonte (2000) consider smoothing models for the estimation of direct variances defined as follows: \\[ \\log\\left(\\hat{\\sigma}_{d}^{2}\\right)=\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}+\\boldsymbol{\\varepsilon}_{d} \\] Where \\(\\boldsymbol{z}_{d}\\) is a vector of explanatory covariates that are functions of \\(\\boldsymbol{x}_{d}\\), \\(\\boldsymbol{\\alpha}\\) is a vector of parameters to be estimated, \\(\\boldsymbol{\\varepsilon}_{d}\\) are random errors with zero mean and constant variance, assumed to be identically distributed conditionally on \\(\\boldsymbol{z}_{d}\\). From the above model, the smoothed estimation of the sampling variance is given by: \\[ \\tilde{\\sigma}_{d}^{2}=E_{\\mathscr{MP}}\\left(\\sigma_{d}^{2}\\right)=\\exp\\left(\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}\\right)\\times\\Delta \\] Where \\(E_{\\mathscr{MP}}\\left(\\varepsilon_{d}\\right)=\\Delta\\). There’s no need to specify a parametric distribution for the errors of this model. Using the method of moments, the following unbiased estimator for \\(\\Delta\\) is obtained: \\[ \\hat{\\Delta}=\\frac{\\sum_{d=1}^{D}\\hat{\\sigma}_{d}^{2}}{\\sum_{d=1}^{D}\\exp\\left(\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}\\right)} \\] Similarly, using standard procedures in linear regression, the estimation of the regression parameter coefficients is given by the following expression: \\[ \\hat{\\boldsymbol{\\alpha}}=\\left(\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\boldsymbol{z}_{d}^{T}\\right)^{-1}\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\log\\left(\\hat{\\sigma}_{d}^{2}\\right) \\] Finally, the smoothed estimator of the sampling variance is defined as: \\[ \\hat{\\tilde{\\sigma}}_{d}^{2}=\\exp\\left(\\boldsymbol{z}_{d}^{T}\\hat{\\boldsymbol{\\alpha}}\\right)\\hat{\\Delta} \\] Survey Data: The following code processes data using various R packages such as survey, tidyverse, srvyr, TeachingSampling, and haven. Library Loading: The code loads the necessary libraries (survey, tidyverse, srvyr, TeachingSampling, haven) required for data manipulation and analysis. Survey Data Set Reading: The code reads the dataset named ‘data_JAM.rds’ using the readRDS function. Data Manipulation: It creates new variables (dam2, fep, upm, estrato, ingreso, pobreza) using the mutate function from the dplyr package. Filters the dataset based on a specific condition using the filter function. library(survey) library(tidyverse) library(srvyr) library(TeachingSampling) library(haven) #read in data set # Q518A: Gross average income From Employment encuesta &lt;- read_rds(&quot;Recursos/02_FGV/01_data_JAM.rds&quot;) encuesta &lt;- encuesta %&gt;% mutate( dam2, fep = RFACT/4, upm = paste0(PAR_COD , CONST_NUMBER, ED_NUMBER), estrato = ifelse(is.na(STRATA) ,strata,STRATA), ingreso = case_when(!is.na(Q518A) &amp; !is.na(Q518B) ~ Q518A + Q518B, !is.na(Q518A) &amp; !is.na(Q518B) ~ NA_real_, !is.na(Q518A) &amp; is.na(Q518B) ~ Q518A, is.na(Q518A) &amp; !is.na(Q518B) ~ Q518B), pobreza = ifelse(ingreso &lt; 50,1,0) ) %&gt;% filter(ingreso &gt; 11) dam2: Corresponds to the code assigned to the country’s second administrative division. The income definition is structured in this manner to illustrate the process utilized in the small area estimation methodology for poverty estimation. ID QUARTER EMPSTATUS STRATA CLUSTER CONST_NUMBER ED_NUMBER URCODE SEX AGE Q518A Q518AP Q518B Q518BP RFACT PAR_COD PARISH strata cluster dam2 fep upm estrato ingreso pobreza 02010105902170101 3 5 014 014011 01 059 1 2 44 9 NA 9e+00 NA 127.4657 01 Kingston NA NA 0101 31.8664 0101059 014 18 1 02020207900130103 3 5 235 235472 02 079 2 1 36 0 NA 1e+05 4 164.6809 12 Manchester NA NA 1202 41.1702 1202079 235 100000 0 02020404901820105 3 5 239 239488 04 049 2 1 25 NA NA 1e+04 3 152.1773 12 Manchester NA NA 1204 38.0443 1204049 239 10000 0 04010400700370102 3 5 036 036073 04 007 1 2 34 9 NA 9e+00 NA 188.7227 02 St Andrew NA NA 0204 47.1807 0204007 036 18 1 04030406400160106 3 5 221 221453 04 064 3 1 20 15000 1 0e+00 NA 308.0567 11 St Elizabeth NA NA 1104 77.0142 1104064 221 15000 0 05020506600550101 3 5 164 164352 05 066 2 2 60 9 NA 9e+00 NA 94.0227 08 St James NA NA 0805 23.5057 0805066 164 18 1 06030106300920101 3 5 122 122227 01 063 3 1 44 9 NA 9e+00 NA 252.1380 05 St Mary NA NA 0501 63.0345 0501063 122 18 1 06030200300140102 3 5 228 228464 02 003 3 2 70 9 NA 9e+00 NA 49.1197 12 Manchester NA NA 1202 12.2799 1202003 228 18 1 06030204100960101 3 5 084 084180 02 041 3 2 54 9 NA 9e+00 NA 97.2597 03 St Thomas NA NA 0302 24.3149 0302041 084 18 1 06030208501550102 3 5 234 234474 02 085 3 2 77 0 NA 3e+04 2 70.9262 12 Manchester NA NA 1202 17.7315 1202085 234 30000 0 In the following code block, the libraries survey and srvyr are used to create a sampling design from a survey database. The sampling design encompasses information about primary sampling units (PSUs), sampling weights (wkx), and strata (estrato) utilized in the sampling. Additionally, the “survey.lonely.psu” option is employed to adjust sample sizes within groups of primary sampling units that lack other primary sampling units within the same group. library(survey) library(srvyr) options(survey.lonely.psu = &quot;adjust&quot;) id_dominio &lt;- &quot;dam2&quot; diseno &lt;- as_survey_design( ids = upm, weights = fep, strata = estrato, nest = TRUE, .data = encuesta ) #summary(diseno) ´ Indicator Calculation: Groups the sampling design by domain ID and calculates indicators related to poverty (n_pobreza and pobreza). n_pobreza counts the number of instances where pobreza equals 1 (indicating poverty), while pobreza computes the survey mean of the pobreza variable with specific variance estimations. # Calculating indicators related to poverty and counts of UPMS per domain # Indicator Calculation: # Grouping the sampling design by domain ID and summarizing variables related to poverty. indicador_dam &lt;- diseno %&gt;% group_by_at(id_dominio) %&gt;% summarise( n_pobreza = unweighted(sum(pobreza == 1)), pobreza = survey_mean(pobreza, vartype = c(&quot;se&quot;, &quot;var&quot;), deff = T ) ) Counts of UPMS per Domain: Extracts domain ID and UPMs from the survey dataset, obtaining unique UPMs per domain and counting them. Joins the count of unique UPMs per domain with the previously calculated indicators related to poverty. # Counts of UPMS per domain: # Selecting domain ID and UPMs, obtaining unique UPMs per domain, and counting them. # Joining the count of unique UPMs per domain with previously calculated indicators related to poverty. indicador_dam &lt;- encuesta %&gt;% select(id_dominio, upm) %&gt;% distinct() %&gt;% group_by_at(id_dominio) %&gt;% tally(name = &quot;n_upm&quot;) %&gt;% inner_join(indicador_dam, by = id_dominio) # saveRDS(directodam2, &quot;Recursos/02_FGV/indicador_dam.Rds&quot;) dam2 n_upm n_pobreza pobreza pobreza_se pobreza_var pobreza_deff 0101 17 237 0.9980 0.0021 0.0000 5.228000e-01 0102 12 197 0.9836 0.0089 0.0001 1.053700e+00 0103 9 65 1.0000 0.0000 0.0000 3.065785e+32 0201 11 244 1.0000 0.0000 0.0000 NaN 0202 11 141 0.9391 0.0292 0.0009 2.317700e+00 0203 12 101 0.8117 0.0775 0.0060 4.795200e+00 0204 11 224 1.0000 0.0000 0.0000 NaN 0205 9 85 0.9646 0.0331 0.0011 2.932600e+00 0206 8 102 1.0000 0.0000 0.0000 NaN 0207 11 149 1.0000 0.0000 0.0000 NaN Ahora se realiza el filtro de los dominios con 5 o más UPMs y todos los que tengan un deff mayor que 1 base_sae &lt;- indicador_dam %&gt;% filter(n_upm &gt;= 5, pobreza_deff &gt; 1) seguidamente se realiza la transformación \\(\\log(\\hat{\\sigma}^2_d)\\), además se realiza la selección de las columnas identificador del municipio (dam2), la estimación directa (pobreza), El número de personas en el dominio (nd) y la varianza estimada del para la estimación directa vardir,siendo esta la que transforma mediante la función log(). baseFGV &lt;- base_sae %&gt;% select(dam2, pobreza, nd = n_pobreza, vardir = pobreza_var) %&gt;% mutate(ln_sigma2 = log(vardir)) "],["graphical-analysis.html", "2.1 Graphical Analysis", " 2.1 Graphical Analysis The first graph, p1, displays a scatter plot of the variable ln_sigma2 against the variable pobreza, with a smooth line representing a trend estimation. The x-axis is labeled as pobreza. The second graph, p2, exhibits a scatter plot of the variable ln_sigma2 against the variable nd, with a smooth line indicating a trend estimation. The x-axis is labeled as Tamaño de muestra (Sample Size). The third graph, p3, demonstrates a scatter plot of the variable ln_sigma2 in relation to the product of pobreza and nd, with a smooth line representing a trend estimation. The x-axis is labeled as Número de pobres (Number of Poor). The fourth graph, p4, shows a scatter plot of the variable ln_sigma2 against the square root of the variable pobreza, with a smooth line representing a trend estimation. The x-axis is labeled as Raiz cuadrada de pobreza (Square Root of Poverty). Overall, these graphs are designed to explore the relationship between ln_sigma2 and different independent variables such as pobreza, nd, and the square root of poverty. Choosing to use the “loess” function to smooth the lines instead of a straight line aids in visualizing general trends in the data more effectively. theme_set(theme_bw()) # pobreza vs Ln_sigma2 # p1 &lt;- ggplot(baseFGV, aes(x = pobreza, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;poverty&quot;) # Sample Size vs Ln_sigma2 # p2 &lt;- ggplot(baseFGV, aes(x = nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Sample size&quot;) # Number of Poor vs Ln_sigma2 # p3 &lt;- ggplot(baseFGV, aes(x = pobreza * nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Number of poor&quot;) # Square Root of Poverty vs Ln_sigma2 # p4 &lt;- ggplot(baseFGV, aes(x = sqrt(pobreza), y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Square root of poverty&quot;) library(patchwork) (p1 | p2) / (p3 | p4) "],["variance-model.html", "2.2 Variance Model", " 2.2 Variance Model The code fits a multiple linear regression model (using the lm() function), where ln_sigma2 is the response variable and the predictor variables include pobreza, nd, and various transformations of these variables. The goal of this model is to estimate the generalized variance function (FGV) for the observed domains. library(gtsummary) FGV1 &lt;- lm(ln_sigma2 ~ -1 + pobreza + I(pobreza*nd), data = baseFGV) tbl_regression(FGV1) %&gt;% add_glance_table(include = c(r.squared, adj.r.squared)) #venishuuyv table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #venishuuyv thead, #venishuuyv tbody, #venishuuyv tfoot, #venishuuyv tr, #venishuuyv td, #venishuuyv th { border-style: none; } #venishuuyv p { margin: 0; padding: 0; } #venishuuyv .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #venishuuyv .gt_caption { padding-top: 4px; padding-bottom: 4px; } #venishuuyv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #venishuuyv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #venishuuyv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #venishuuyv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #venishuuyv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #venishuuyv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #venishuuyv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #venishuuyv .gt_column_spanner_outer:first-child { padding-left: 0; } #venishuuyv .gt_column_spanner_outer:last-child { padding-right: 0; } #venishuuyv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #venishuuyv .gt_spanner_row { border-bottom-style: hidden; } #venishuuyv .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #venishuuyv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #venishuuyv .gt_from_md > :first-child { margin-top: 0; } #venishuuyv .gt_from_md > :last-child { margin-bottom: 0; } #venishuuyv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #venishuuyv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #venishuuyv .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #venishuuyv .gt_row_group_first td { border-top-width: 2px; } #venishuuyv .gt_row_group_first th { border-top-width: 2px; } #venishuuyv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #venishuuyv .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #venishuuyv .gt_first_summary_row.thick { border-top-width: 2px; } #venishuuyv .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #venishuuyv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #venishuuyv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #venishuuyv .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #venishuuyv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #venishuuyv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #venishuuyv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #venishuuyv .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #venishuuyv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #venishuuyv .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #venishuuyv .gt_left { text-align: left; } #venishuuyv .gt_center { text-align: center; } #venishuuyv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #venishuuyv .gt_font_normal { font-weight: normal; } #venishuuyv .gt_font_bold { font-weight: bold; } #venishuuyv .gt_font_italic { font-style: italic; } #venishuuyv .gt_super { font-size: 65%; } #venishuuyv .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #venishuuyv .gt_asterisk { font-size: 100%; vertical-align: 0; } #venishuuyv .gt_indent_1 { text-indent: 5px; } #venishuuyv .gt_indent_2 { text-indent: 10px; } #venishuuyv .gt_indent_3 { text-indent: 15px; } #venishuuyv .gt_indent_4 { text-indent: 20px; } #venishuuyv .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value pobreza -12 -20, -4.5 0.003 I(pobreza * nd) 0.02 -0.04, 0.07 0.5 R² 0.345 Adjusted R² 0.311 1 CI = Confidence Interval After obtaining the model estimation, the value of the constant \\(\\Delta\\) must be obtained, for which the following code is used. delta.hat = sum(baseFGV$vardir) / sum(exp(fitted.values(FGV1))) From which it is derived that \\(\\Delta = 0.110434\\). Finally, it is possible to obtain the smoothed variance by executing the following command. hat.sigma &lt;- data.frame(dam2 = baseFGV$dam2, hat_var = delta.hat * exp(fitted.values(FGV1))) baseFGV &lt;- left_join(baseFGV, hat.sigma) tba(head(baseFGV, 10)) dam2 pobreza nd vardir ln_sigma2 hat_var 0102 0.9836 197 0.0001 -9.4372 0e+00 0103 1.0000 65 0.0000 -76.3620 0e+00 0202 0.9391 141 0.0009 -7.0701 0e+00 0203 0.8117 101 0.0060 -5.1159 0e+00 0205 0.9646 85 0.0011 -6.8149 0e+00 0212 0.8304 59 0.0101 -4.5936 0e+00 0301 0.9419 45 0.0013 -6.6569 0e+00 0302 0.9109 159 0.0017 -6.3681 0e+00 0401 0.8063 319 0.0006 -7.4369 4e-04 0402 0.8311 259 0.0012 -6.7172 1e-04 Model validation for the FGV par(mfrow = c(2, 2)) plot(FGV1) Smoothed variance prediction base_sae &lt;- left_join(indicador_dam, baseFGV %&gt;% select(id_dominio, hat_var), by = id_dominio) %&gt;% mutate( pobreza_var = ifelse(is.na(hat_var), NA_real_, pobreza_var), pobreza_deff = ifelse(is.na(hat_var), NA_real_, pobreza_deff) ) Now, we make a line graph to see the volatility and the estimates of the variances. nDom &lt;- sum(!is.na(base_sae$hat_var)) temp_FH &lt;- base_sae %&gt;% filter(!is.na(hat_var)) ggplot(temp_FH %&gt;% arrange(n_pobreza), aes(x = 1:nDom)) + geom_line(aes(y = pobreza_var, color = &quot;VarDirEst&quot;)) + geom_line(aes(y = hat_var, color = &quot;FGV&quot;)) + labs(y = &quot;Varianzas&quot;, x = &quot;Sample size&quot;, color = &quot; &quot;) + scale_x_continuous(breaks = seq(1, nDom, by = 10), labels = temp_FH$n_pobreza[order(temp_FH$n_pobreza)][seq(1, nDom, by = 10)]) + scale_color_manual(values = c(&quot;FGV&quot; = &quot;Blue&quot;, &quot;VarDirEst&quot; = &quot;Red&quot;)) This code performs several transformations on the dataset base_sae: Creation of new variables: pobreza_deff: Replaces NaN values with 1 if they exist; otherwise, it keeps the original value. deff_FGV: Computes a new Design Effect (DEFF) using the formula hat_var / (pobreza_var / pobreza_deff) when pobreza_var is not equal to 0. n_eff_FGV: Calculates the effective number of surveyed individuals as n_pobreza / deff_FGV. Modification of the variable pobreza: If hat_var is NA, it replaces pobreza values with NA; otherwise, it retains the original value. base_FH &lt;- base_sae %&gt;% mutate( pobreza_deff = ifelse(is.nan(pobreza_deff), 1, pobreza_deff), deff_FGV = ifelse(pobreza_var == 0 , 1, hat_var / (pobreza_var / pobreza_deff) #Fórmula del nuevo DEFF ), # Criterio MDS para regularizar el DeffFGV n_eff_FGV = n_pobreza / deff_FGV, #Número efectivo de personas encuestadas pobreza = ifelse(is.na(hat_var), NA_real_, pobreza) ) #saveRDS(object = base_FH, &quot;Recursos/02_FGV/base_FH_2020.rds&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
